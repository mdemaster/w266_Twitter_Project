{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Project Milestone Code\n",
    "Marcus DeMaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collect Labeled Subjects and Tweet Histories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting \"I have health insurance\" tweets from 2017-09-01 to 2017-11-17 and a tweet-history of 50 past tweets\n",
      "\n",
      "-----100 tweets collected at 2017-11-17 20:28:07.611147.\n",
      "-----200 tweets collected at 2017-11-17 20:29:41.832015.\n",
      "-----300 tweets collected at 2017-11-17 20:31:14.246511.\n",
      "-----400 tweets collected at 2017-11-17 20:32:45.796151.\n",
      "-----500 tweets collected at 2017-11-17 20:44:35.886277.\n",
      "-----600 tweets collected at 2017-11-17 20:46:10.498302.\n",
      "-----700 tweets collected at 2017-11-17 20:47:35.400911.\n",
      "-----741 \"I have health insurance\" tweets collected in 0:22:19.339171 seconds.\n",
      "\n",
      "Collecting \"I don't have health insurance\" tweets from 2017-09-01 to 2017-11-17 and a tweet-history of 50 past tweets\n",
      "\n",
      "-----100 tweets collected at 2017-11-17 20:59:57.658332.\n",
      "-----200 tweets collected at 2017-11-17 21:01:24.124802.\n",
      "-----300 tweets collected at 2017-11-17 21:02:59.551815.\n",
      "-----400 tweets collected at 2017-11-17 21:14:35.203064.\n",
      "-----500 tweets collected at 2017-11-17 21:16:08.609713.\n",
      "-----600 tweets collected at 2017-11-17 21:17:38.573992.\n",
      "-----631 \"I don't have health insurance\" tweets collected in 0:29:54.572678 seconds.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import tweepy\n",
    "import json\n",
    "\n",
    "#Twitter API Credentials for using tweepy\n",
    "consumer_key = \"zX6qyiIyZze3gu5r1We9IUgqY\"\n",
    "consumer_secret = \"NeU4ossMcQziXIiAqc6xxLwiojdnwIhFrgeCuJlWoInrHyKmxM\";\n",
    "access_token = \"837785154651238400-zVPiieFeIFH7LQq4XGFPuj2UGNsRXZS\";\n",
    "access_token_secret = \"9EwL5ov6Ej99zpUPkyKCdOUMVnov8paUTPpgWYcsbBigF\";\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)  \n",
    "\n",
    "#Set empty list to append json objects\n",
    "tjson=[]\n",
    "\n",
    "#Set search parameters for model subject tweets to be webscraped.\n",
    "start='2017-09-01'\n",
    "end='2017-11-17'\n",
    "querylist=[\"I have health insurance\",\"I don't have health insurance\"]\n",
    "\n",
    "#Number of tweets from user history to collect\n",
    "tweethistcount=50\n",
    "\n",
    "#Query tweets stating they do and do not have health insurance.\n",
    "for label,query in enumerate(querylist):\n",
    "    print\n",
    "    print 'Collecting \"%s\" tweets from %s to %s and a tweet-history of %s past tweets'%(query,start,end,tweethistcount)\n",
    "    print\n",
    "    startTime = datetime.now()\n",
    "    q=query.replace(' ','%20')\n",
    "    prefix='https://twitter.com/search?f=tweets&vertical=default&q=%22'\n",
    "    browser = webdriver.Chrome('./chromedriver')\n",
    "    browser.get(prefix+q+'%22%20since%3A'+start+'%20until%3A'+end+'&src=typd')\n",
    "    \n",
    "    #Scroll to bottom of search results page to webscrape all results.\n",
    "    while True:\n",
    "        elemsCount = browser.execute_script(\"return document.querySelectorAll('.stream-items > li.stream-item').length\")\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        try:\n",
    "            WebDriverWait(browser, 2).until(lambda x: x.find_element_by_xpath(\n",
    "                \"//*[contains(@class,'stream-items')]/li[contains(@class,'stream-item')][\"+str(elemsCount+1)+\"]\"))\n",
    "        except:\n",
    "            break  \n",
    "    \n",
    "    #Get lists of all tweets, usernames, and dates\n",
    "    tweets = browser.find_elements_by_class_name('js-tweet-text')\n",
    "    tweetids = browser.find_elements_by_css_selector('li.js-stream-item')\n",
    "    users = browser.find_elements_by_css_selector('.original-tweet')\n",
    "    dates = browser.find_elements_by_class_name('tweet-timestamp')\n",
    "    \n",
    "    twtcnt=0\n",
    "    \n",
    "    #Loop through tweet info and assign to dict\n",
    "    for user,date,tweetid,tweet in zip(users,dates,tweetids,tweets):\n",
    "        tdata={}\n",
    "        tdata['tweet_id']=tweetid.find_element_by_css_selector('.time a.tweet-timestamp').get_attribute('data-conversation-id')\n",
    "        tdata['label']=label\n",
    "        tdata['tweetdate']=date.get_attribute('title')\n",
    "        tdata['username']=user.get_attribute('data-screen-name')\n",
    "        tdata['tweettext']=tweet.text.encode(\"utf-8\")\n",
    "#         \\\n",
    "#         .decode('unicode_escape')\\\n",
    "#         .encode('ascii','ignore')\\\n",
    "#         .replace('\"', '\"\"')\\\n",
    "#         .replace('\\n', ' ')\\\n",
    "#         .replace('\\r', ' ')\\\n",
    "#         .replace('  ', ' ')\\\n",
    "#         .replace(',',' ')\n",
    "        \n",
    "        #Ignore tweets in quotes and from bots\n",
    "        T=tdata['tweettext'].upper()\n",
    "        Q=query.upper()\n",
    "        #all(['\"' in T.split(Q,1)[0], '\"' in T.split(Q,1)[1]]) or \n",
    "        if any(['bot' in tdata['username'],'censusAmericans'in tdata['username']]):\n",
    "            continue\n",
    "        else:\n",
    "            twtcnt+=1\n",
    "            pasttweets=[]\n",
    "            pasttweetdates=[]\n",
    "            #For eligible subjects, use API to search prior user timeline tweets and add to dict\n",
    "            for status in tweepy.Cursor(\n",
    "                    api.user_timeline,\n",
    "                    tdata['username'],\n",
    "                    max_id=int(tdata['tweet_id'])-1\n",
    "                    ).items(tweethistcount):\n",
    "                pasttweet=status.text.encode(\"utf-8\")#\\\n",
    "                #.decode('unicode_escape')\\\n",
    "                #.encode('ascii','ignore')\\\n",
    "                #.replace('\\n', ' ')\\\n",
    "                #.replace('\\r', ' ')\\\n",
    "                #.replace('  ', ' ')\\\n",
    "                #.replace(',',' ')\n",
    "                pasttweets.append(pasttweet)\n",
    "                pasttweetdates.append(str(status.created_at))\n",
    "            tdata['pasttweets']=pasttweets\n",
    "            tdata['pasttweetdates']=pasttweetdates\n",
    "            tjson.append(tdata)    \n",
    "        if twtcnt % 100 == 0:\n",
    "            print '-----%s tweets collected at %s.'%(twtcnt,datetime.now())\n",
    "    browser.quit()\n",
    "    print '-----%s \"%s\" tweets collected in %s seconds.'%(twtcnt,query,datetime.now()-startTime)\n",
    "\n",
    "#Write dicts to json file.\n",
    "with open('testtweets.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(tjson))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pasttweetdates</th>\n",
       "      <th>pasttweets</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweetdate</th>\n",
       "      <th>tweettext</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2017-11-16 22:52:05, 2017-11-16 22:49:26, 201...</td>\n",
       "      <td>[I'm tirrrrrred, @HarrisHarrisev9 Such truth!!...</td>\n",
       "      <td>931295366527553536</td>\n",
       "      <td>2:58 PM - 16 Nov 2017</td>\n",
       "      <td>I have health insurance now so that's good</td>\n",
       "      <td>thatwitchlefay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[2017-11-16 21:27:45, 2017-11-16 21:18:49, 201...</td>\n",
       "      <td>[RT @nytopinion: The House just passed a bill ...</td>\n",
       "      <td>931272809594093568</td>\n",
       "      <td>2:15 PM - 16 Nov 2017</td>\n",
       "      <td>I teach one section of first-year writing each...</td>\n",
       "      <td>the_author_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[2017-11-16 21:53:13, 2017-11-16 21:51:46, 201...</td>\n",
       "      <td>[RT @illscum: honestly at this point the probl...</td>\n",
       "      <td>931279638734757888</td>\n",
       "      <td>1:55 PM - 16 Nov 2017</td>\n",
       "      <td>I literally take a medication for my addiction...</td>\n",
       "      <td>37notmywife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[2017-11-16 16:03:04, 2017-11-16 05:55:37, 201...</td>\n",
       "      <td>[@TomJurgensen @sirdinitski I literally just g...</td>\n",
       "      <td>931202725366386688</td>\n",
       "      <td>8:50 AM - 16 Nov 2017</td>\n",
       "      <td>I have health insurance again so I’m bout to b...</td>\n",
       "      <td>spotifyisokay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[2017-11-16 02:01:12, 2017-11-16 01:55:40, 201...</td>\n",
       "      <td>[RT @WayneDupreeShow: I AM NOT A COLOR. I am a...</td>\n",
       "      <td>931065177906216960</td>\n",
       "      <td>8:10 AM - 16 Nov 2017</td>\n",
       "      <td>They will not lose healthcare, they will lose ...</td>\n",
       "      <td>Sheeple15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                     pasttweetdates  \\\n",
       "0      0  [2017-11-16 22:52:05, 2017-11-16 22:49:26, 201...   \n",
       "1      0  [2017-11-16 21:27:45, 2017-11-16 21:18:49, 201...   \n",
       "2      0  [2017-11-16 21:53:13, 2017-11-16 21:51:46, 201...   \n",
       "3      0  [2017-11-16 16:03:04, 2017-11-16 05:55:37, 201...   \n",
       "4      0  [2017-11-16 02:01:12, 2017-11-16 01:55:40, 201...   \n",
       "\n",
       "                                          pasttweets            tweet_id  \\\n",
       "0  [I'm tirrrrrred, @HarrisHarrisev9 Such truth!!...  931295366527553536   \n",
       "1  [RT @nytopinion: The House just passed a bill ...  931272809594093568   \n",
       "2  [RT @illscum: honestly at this point the probl...  931279638734757888   \n",
       "3  [@TomJurgensen @sirdinitski I literally just g...  931202725366386688   \n",
       "4  [RT @WayneDupreeShow: I AM NOT A COLOR. I am a...  931065177906216960   \n",
       "\n",
       "               tweetdate                                          tweettext  \\\n",
       "0  2:58 PM - 16 Nov 2017         I have health insurance now so that's good   \n",
       "1  2:15 PM - 16 Nov 2017  I teach one section of first-year writing each...   \n",
       "2  1:55 PM - 16 Nov 2017  I literally take a medication for my addiction...   \n",
       "3  8:50 AM - 16 Nov 2017  I have health insurance again so I’m bout to b...   \n",
       "4  8:10 AM - 16 Nov 2017  They will not lose healthcare, they will lose ...   \n",
       "\n",
       "         username  \n",
       "0  thatwitchlefay  \n",
       "1     the_author_  \n",
       "2     37notmywife  \n",
       "3   spotifyisokay  \n",
       "4       Sheeple15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read json with pandas and inspect\n",
    "import pandas as pd\n",
    "d = pd.read_json('testtweets.json')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    741\n",
       "1    631\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect label balance\n",
    "d.groupby('label')['tweet_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pasttweets\n",
       "0      127\n",
       "1        2\n",
       "2        1\n",
       "4        2\n",
       "5        1\n",
       "9        1\n",
       "11       2\n",
       "12       1\n",
       "15       1\n",
       "16       1\n",
       "17       1\n",
       "18       2\n",
       "19       2\n",
       "20       1\n",
       "21       3\n",
       "23       1\n",
       "25       2\n",
       "28       1\n",
       "30       1\n",
       "32       2\n",
       "33       1\n",
       "40       1\n",
       "41       4\n",
       "42       1\n",
       "45       1\n",
       "47       1\n",
       "50    1208\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect distribution of subjects by prior tweet history volumes\n",
    "d.groupby(d['pasttweets'].str.len())['tweet_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert list of past tweets to text for modeling.\n",
    "d['pasttweets_text']=d['pasttweets'].apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split subjects into train and test sets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "train_tweets, dev_tweets = train_test_split(d, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create TFIDF vectors for modeling\n",
    "vectorizer = TfidfVectorizer(max_df=0.1)  \n",
    "train_tweets_vector = vectorizer.fit_transform(train_tweets['pasttweets_text'])\n",
    "dev_tweets_vector = vectorizer.transform(dev_tweets['pasttweets_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Scoring Function\n",
    "def PerformLogisticRegression(c, train_data, train_labels, dev_data, dev_labels):\n",
    "    model = LogisticRegression(C=c ,class_weight='balanced')\n",
    "    model.fit(train_data, train_labels)   \n",
    "    predicted_labels = model.predict(dev_data)\n",
    "    \n",
    "    #scores\n",
    "    score = metrics.f1_score(dev_labels,predicted_labels, pos_label = 1)\n",
    "    f1a, f1b =metrics.f1_score(dev_labels,predicted_labels, average=None)\n",
    "    precision = metrics.precision_score(dev_labels,predicted_labels, pos_label = 1)\n",
    "    accuracy = np.mean(predicted_labels == dev_labels) \n",
    "    \n",
    "    #roc_auc\n",
    "    predicted_prob = model.predict_proba(dev_data) \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels, predicted_prob[:,1], pos_label = 1)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print ' C: %3.5f ,  accuracy: %3.5f , precision-score:%3.5f,  f1-score: %3.5f, (%3.5f,%3.5f)  roc_auc: %3.5f ' %(c,  accuracy,precision,score , f1a, f1b, roc_auc )\n",
    "    return (score, precision, accuracy,  model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C: 0.00010 ,  accuracy: 0.56727 , precision-score:0.53600,  f1-score: 0.52964, (0.59933,0.52964)  roc_auc: 0.59439 \n",
      " C: 0.00100 ,  accuracy: 0.57091 , precision-score:0.53968,  f1-score: 0.53543, (0.60135,0.53543)  roc_auc: 0.59439 \n",
      " C: 0.01000 ,  accuracy: 0.57818 , precision-score:0.54545,  f1-score: 0.55385, (0.60000,0.55385)  roc_auc: 0.59455 \n",
      " C: 0.10000 ,  accuracy: 0.58545 , precision-score:0.55072,  f1-score: 0.57143, (0.59859,0.57143)  roc_auc: 0.59683 \n",
      " C: 0.50000 ,  accuracy: 0.58909 , precision-score:0.55474,  f1-score: 0.57358, (0.60351,0.57358)  roc_auc: 0.59662 \n",
      " C: 1.00000 ,  accuracy: 0.58182 , precision-score:0.54815,  f1-score: 0.56274, (0.59930,0.56274)  roc_auc: 0.59673 \n",
      " C: 5.00000 ,  accuracy: 0.56727 , precision-score:0.53600,  f1-score: 0.52964, (0.59933,0.52964)  roc_auc: 0.59327 \n",
      " C: 10.00000 ,  accuracy: 0.57455 , precision-score:0.54472,  f1-score: 0.53386, (0.60870,0.53386)  roc_auc: 0.59035 \n"
     ]
    }
   ],
   "source": [
    "# Scan for the best C value \n",
    "c_values =  [ 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0 ]\n",
    "max_score = 0;\n",
    "max_set =()\n",
    "for c in c_values:\n",
    "    score, precision, accuracy, model = PerformLogisticRegression(\n",
    "        c, train_tweets_vector, train_tweets['label'], dev_tweets_vector, dev_tweets['label'])\n",
    "    \n",
    "    if (score > max_score):\n",
    "        max_score = score\n",
    "        max_set = (c,accuracy, score, precision, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
